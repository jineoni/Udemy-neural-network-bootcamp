{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Torch Tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D Tensor\n",
    "a = torch.tensor([2, 2, 1])\n",
    "\n",
    "# 2D Tensor\n",
    "b = torch.tensor([[2, 1, 4], [3, 5, 4], [1, 2, 0], [4, 3, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([3])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# The size of the tensors\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(a.size())\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.FloatTensor([[2, 1, 4], [3, 5, 4], [1, 2, 0], [4, 3, 2]])\n",
    "# or we can do\n",
    "# c = torch.tensor([[2, 1, 4], [3, 5, 4], [1, 2, 0], [4, 3, 2]], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.DoubleTensor([[2, 1, 4], [3, 5, 4], [1, 2, 0], [4, 3, 2]])\n",
    "# or we can do\n",
    "# d = torch.tensor([[2, 1, 4], [3, 5, 4], [1, 2, 0], [4, 3, 2]], dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5833)\n",
      "tensor(2.5833, dtype=torch.float64)\n",
      "tensor(1.5050)\n",
      "tensor(1.5050, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(c.mean())\n",
    "print(d.mean())\n",
    "print(c.std())\n",
    "print(d.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [1],\n",
      "        [4],\n",
      "        [3],\n",
      "        [5],\n",
      "        [4],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [4],\n",
      "        [3],\n",
      "        [2]])\n",
      "tensor([2, 1, 4, 3, 5, 4, 1, 2, 0, 4, 3, 2])\n",
      "tensor([[2, 1, 4, 3],\n",
      "        [5, 4, 1, 2],\n",
      "        [0, 4, 3, 2]])\n"
     ]
    }
   ],
   "source": [
    "# Reshape b\n",
    "# Note: If one of the dimensions is -1, its size can be inferred.\n",
    "print(b.view(-1, 1)) # 2D, 12x1\n",
    "print(b.view(12)) # 1D\n",
    "print(b.view(-1, 4)) # 2D, 3x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign b a new shape\n",
    "b = b.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8250, 0.7701, 0.5037, 0.0440],\n",
      "        [0.1334, 0.1473, 0.6698, 0.9654],\n",
      "        [0.1919, 0.0200, 0.7133, 0.9215],\n",
      "        [0.7472, 0.1742, 0.6076, 0.1108]])\n",
      "tensor([[-0.4698, -1.3389, -1.7324, -0.6276],\n",
      "        [-0.2555,  0.5492,  1.4100,  0.4525],\n",
      "        [ 2.0714,  0.7245,  1.7843, -0.0947],\n",
      "        [-1.3158, -1.9029, -0.9036,  0.2475]])\n",
      "tensor([[0.2953, 0.6435, 0.6834, 0.6381],\n",
      "        [0.2033, 0.0030, 0.4213, 0.5902],\n",
      "        [0.6930, 0.1634, 0.7808, 0.0200],\n",
      "        [0.6033, 0.6790, 0.5795, 0.0236]], dtype=torch.float64)\n",
      "tensor([7, 9, 7, 8, 6])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with random numbers\n",
    "\n",
    "# numbers between 0 and 1\n",
    "r1 = torch.rand(4, 4)\n",
    "print(r1)\n",
    "\n",
    "# numbers taken from a normal distribution with mean 0 and variance 1\n",
    "r2 = torch.randn(4, 4)\n",
    "print(r2)\n",
    "\n",
    "r2_like = torch.rand_like(r2, dtype=torch.double)\n",
    "print(r2_like)\n",
    "\n",
    "# numbers from values between 6 and 9 (exclusive of 10)\n",
    "r3 = torch.randint(6, 10, (5, ))\n",
    "print(r3)\n",
    "print(r3.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1405, -1.0496,  1.3540, -0.3124],\n",
      "         [-0.9289,  0.8527,  0.6104,  1.5247],\n",
      "         [ 0.4927,  0.0996,  0.6537,  0.8977]],\n",
      "\n",
      "        [[-0.8913,  0.5585,  0.4247,  1.7875],\n",
      "         [ 0.3998,  2.3096,  0.0236,  0.6760],\n",
      "         [-0.6968, -1.5419,  0.2704, -0.2920]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 3D Tensor with 2 channels, 3 rows, and 4 columns\n",
    "three_dim = torch.randn(2, 3, 4)\n",
    "print(three_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# Get the number of elements in a tensor\n",
    "print(torch.numel(three_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "torch.int64\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create a 3x3 tensor of zeros and of dtype long\n",
    "z = torch.zeros(3, 3, dtype=torch.long)\n",
    "print(z)\n",
    "print(z.dtype)\n",
    "\n",
    "# Create a 3x3 tensor of ones\n",
    "o = torch.ones(3, 3)\n",
    "print(o)\n",
    "print(o.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1802,  0.2013, -0.7250, -0.5397],\n",
      "        [ 0.0112,  0.8439,  2.7496,  2.3833],\n",
      "        [ 2.4551,  0.7644,  3.2108,  1.7483],\n",
      "        [ 0.1786, -1.5545,  0.3116,  0.4691]])\n",
      "tensor([[ 1.1802,  0.2013, -0.7250, -0.5397],\n",
      "        [ 0.0112,  0.8439,  2.7496,  2.3833],\n",
      "        [ 2.4551,  0.7644,  3.2108,  1.7483],\n",
      "        [ 0.1786, -1.5545,  0.3116,  0.4691]])\n"
     ]
    }
   ],
   "source": [
    "# Add two tensors\n",
    "# Note: Make sure they are the same size and data type.\n",
    "add_result = torch.add(r1, r2)\n",
    "print(add_result)\n",
    "\n",
    "# in-place addition\n",
    "r2.add_(r1)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2013,  0.8439,  0.7644, -1.5545])\n",
      "tensor([[ 1.1802,  0.2013],\n",
      "        [ 0.0112,  0.8439],\n",
      "        [ 2.4551,  0.7644],\n",
      "        [ 0.1786, -1.5545]])\n",
      "tensor(1.7483)\n",
      "1.7482578754425049\n"
     ]
    }
   ],
   "source": [
    "# Indexing and Slicing\n",
    "print(r2[:, 1])\n",
    "print(r2[:, :2])\n",
    "\n",
    "num = r2[2, 3]\n",
    "print(num)\n",
    "print(num.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numpy Bridge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Convert a torch tensor to a numpy array\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 5., 5., 5., 5.])\n",
      "[5. 5. 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "# Note: Numpy Bridge, Whatever happens on the torch tensor also happens on the numpy array.\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Convert a numpy array to a torch tensor\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 4, 1]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Convert a list to a torch tensor\n",
    "a = [2, 3, 4, 1]\n",
    "b = torch.tensor(a)\n",
    "print(b, b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Move the tensor to the GPU\n",
    "# when you wanna do some GPU calculations to speed up the computations\n",
    "\n",
    "CUDA = torch.cuda.is_available()\n",
    "print(CUDA)\n",
    "\n",
    "if CUDA:\n",
    "    r2 = r2.cuda()\n",
    "    print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tensor Concatenation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2121,  0.7382,  0.0659,  1.4702,  0.2325],\n",
      "        [ 0.5640,  0.4856,  0.3835, -0.4699,  0.5867]])\n",
      "tensor([[-0.7882, -0.4782,  1.6111, -0.9088,  0.0425],\n",
      "        [-2.0686,  0.2144,  1.3320, -2.1714,  1.0113],\n",
      "        [ 0.2157, -0.5015, -0.0505,  0.5351,  0.8151]])\n",
      "\n",
      "\n",
      "tensor([[ 1.2121,  0.7382,  0.0659,  1.4702,  0.2325],\n",
      "        [ 0.5640,  0.4856,  0.3835, -0.4699,  0.5867],\n",
      "        [-0.7882, -0.4782,  1.6111, -0.9088,  0.0425],\n",
      "        [-2.0686,  0.2144,  1.3320, -2.1714,  1.0113],\n",
      "        [ 0.2157, -0.5015, -0.0505,  0.5351,  0.8151]])\n"
     ]
    }
   ],
   "source": [
    "first_1 = torch.randn(2, 5)\n",
    "second_1 = torch.randn(3, 5)\n",
    "print(first_1)\n",
    "print(second_1)\n",
    "print('\\n')\n",
    "\n",
    "# Concatenate along the 0 dimension (i.e. concatenate rows)\n",
    "con_1 = torch.cat([first_1, second_1])\n",
    "print(con_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7858, -0.6263,  1.1338],\n",
      "        [-2.0142,  0.5903,  1.3785]])\n",
      "tensor([[-1.0393, -1.1257, -0.3789, -0.3815, -0.0351],\n",
      "        [ 0.2819, -0.0121,  0.8678, -1.0244, -0.0642]])\n",
      "\n",
      "\n",
      "tensor([[ 1.7858, -0.6263,  1.1338, -1.0393, -1.1257, -0.3789, -0.3815, -0.0351],\n",
      "        [-2.0142,  0.5903,  1.3785,  0.2819, -0.0121,  0.8678, -1.0244, -0.0642]])\n"
     ]
    }
   ],
   "source": [
    "first_2 = torch.randn(2, 3)\n",
    "second_2 = torch.randn(2, 5)\n",
    "print(first_2)\n",
    "print(second_2)\n",
    "print('\\n')\n",
    "\n",
    "# Concatentate along the 1 dimension (i.e. concatenate columns)\n",
    "con_2 = torch.cat([first_2, second_2], 1)\n",
    "print(con_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Adding Dimensions to Tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n",
      "torch.Size([1, 4])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# Add a dimension of 1 along a specified index\n",
    "tensor_1 = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "tensor_a = torch.unsqueeze(tensor_1, 0)\n",
    "print(tensor_a)\n",
    "print(tensor_a.shape)\n",
    "\n",
    "tensor_b = torch.unsqueeze(tensor_1, 1)\n",
    "print(tensor_b)\n",
    "print(tensor_b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **AutoGrad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000002032BE934C0>\n"
     ]
    }
   ],
   "source": [
    "# Note: If requires_grad=True, the tensor object keeps track of how it was created.\n",
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "y = torch.tensor([4., 5., 6.], requires_grad=True)\n",
    "\n",
    "# Check which operation was used to create the corresponding variable.\n",
    "z = x + y\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SumBackward0 object at 0x000002032BF30580>\n"
     ]
    }
   ],
   "source": [
    "s = z.sum() # the sum of all elements in z\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# If we backpropagate on s, we can find the gradients of s with respect to x.\n",
    "s.backward() # compute all the gradients at once in the graph\n",
    "print(x.grad) # access the gradients of s with respect to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "None\n",
      "<AddBackward0 object at 0x000002032C0AB010>\n"
     ]
    }
   ],
   "source": [
    "# By default, tensors have requires_grad = False\n",
    "x = torch.randn(2, 2)\n",
    "y = torch.randn(2, 2)\n",
    "print(x.requires_grad, y.requires_grad)\n",
    "\n",
    "z = x + y\n",
    "# Can't backpropagate through z\n",
    "print(z.grad_fn)\n",
    "\n",
    "# Modify and set requires_grad = True\n",
    "x.requires_grad_()\n",
    "y.requires_grad_()\n",
    "\n",
    "z = x + y\n",
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# z.detach() returns a tensor that shares the same storage as z, but with the computation history forgotten.\n",
    "new_z = z.detach()\n",
    "print(new_z.grad_fn) # None, because it doesn't know anything about how it was computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Stop autograd from tracking history on tensors\n",
    "print(x.requires_grad)\n",
    "print((x+10).requires_grad)\n",
    "with torch.no_grad():\n",
    "    print((x+10).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x000002032C091840>\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n",
      "\n",
      "\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "### EXAMPLE\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z)\n",
    "print(out)\n",
    "print('\\n')\n",
    "\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
